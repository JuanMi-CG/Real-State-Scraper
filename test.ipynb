{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import inmocasal\n",
    "import axius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 16:55:27,029 - srap_logging - INFO - Skipping download: axius\\page_1.html already exists.\n",
      "2024-12-07 16:55:31,215 - srap_logging - INFO - Total Properties: 147\n",
      "2024-12-07 16:55:31,216 - srap_logging - INFO - ----------------------------------------------------------------------------------------------------\n",
      "2024-12-07 16:55:31,216 - srap_logging - INFO - Scraping page 1/13...\n",
      "2024-12-07 16:55:31,217 - srap_logging - INFO - Skipping download: axius\\page_1.html already exists.\n",
      "2024-12-07 16:55:31,276 - srap_logging - INFO - Number of items: 227\n",
      "2024-12-07 16:55:31,277 - srap_logging - INFO - ----------------------------------------------------------------------------------------------------\n",
      "2024-12-07 16:55:31,278 - srap_logging - INFO - Scraping page 2/13...\n",
      "2024-12-07 16:55:31,279 - srap_logging - INFO - Skipping download: axius\\page_2.html already exists.\n",
      "2024-12-07 16:55:31,345 - srap_logging - INFO - Number of items: 227\n",
      "2024-12-07 16:55:31,346 - srap_logging - INFO - ----------------------------------------------------------------------------------------------------\n",
      "2024-12-07 16:55:31,347 - srap_logging - INFO - Scraping page 3/13...\n",
      "2024-12-07 16:55:31,348 - srap_logging - INFO - Skipping download: axius\\page_3.html already exists.\n",
      "2024-12-07 16:55:31,413 - srap_logging - INFO - Number of items: 227\n",
      "2024-12-07 16:55:31,414 - srap_logging - INFO - ----------------------------------------------------------------------------------------------------\n",
      "2024-12-07 16:55:31,414 - srap_logging - INFO - Scraping page 4/13...\n",
      "2024-12-07 16:55:31,415 - srap_logging - INFO - Skipping download: axius\\page_4.html already exists.\n",
      "2024-12-07 16:55:31,484 - srap_logging - INFO - Number of items: 227\n",
      "2024-12-07 16:55:31,485 - srap_logging - INFO - ----------------------------------------------------------------------------------------------------\n",
      "2024-12-07 16:55:31,486 - srap_logging - INFO - Scraping page 5/13...\n",
      "2024-12-07 16:55:31,487 - srap_logging - INFO - Skipping download: axius\\page_5.html already exists.\n",
      "2024-12-07 16:55:31,561 - srap_logging - INFO - Number of items: 227\n",
      "2024-12-07 16:55:31,562 - srap_logging - INFO - ----------------------------------------------------------------------------------------------------\n",
      "2024-12-07 16:55:31,562 - srap_logging - INFO - Scraping page 6/13...\n",
      "2024-12-07 16:55:31,563 - srap_logging - INFO - Skipping download: axius\\page_6.html already exists.\n",
      "2024-12-07 16:55:31,643 - srap_logging - INFO - Number of items: 227\n",
      "2024-12-07 16:55:31,644 - srap_logging - INFO - ----------------------------------------------------------------------------------------------------\n",
      "2024-12-07 16:55:31,645 - srap_logging - INFO - Scraping page 7/13...\n",
      "2024-12-07 16:55:31,645 - srap_logging - INFO - Skipping download: axius\\page_7.html already exists.\n",
      "2024-12-07 16:55:31,718 - srap_logging - INFO - Number of items: 227\n",
      "2024-12-07 16:55:31,719 - srap_logging - INFO - ----------------------------------------------------------------------------------------------------\n",
      "2024-12-07 16:55:31,720 - srap_logging - INFO - Scraping page 8/13...\n",
      "2024-12-07 16:55:31,721 - srap_logging - INFO - Skipping download: axius\\page_8.html already exists.\n",
      "2024-12-07 16:55:31,799 - srap_logging - INFO - Number of items: 227\n",
      "2024-12-07 16:55:31,800 - srap_logging - INFO - ----------------------------------------------------------------------------------------------------\n",
      "2024-12-07 16:55:31,801 - srap_logging - INFO - Scraping page 9/13...\n",
      "2024-12-07 16:55:31,802 - srap_logging - INFO - Skipping download: axius\\page_9.html already exists.\n",
      "2024-12-07 16:55:31,970 - srap_logging - INFO - Number of items: 227\n",
      "2024-12-07 16:55:31,971 - srap_logging - INFO - ----------------------------------------------------------------------------------------------------\n",
      "2024-12-07 16:55:31,972 - srap_logging - INFO - Scraping page 10/13...\n",
      "2024-12-07 16:55:31,973 - srap_logging - INFO - Skipping download: axius\\page_10.html already exists.\n",
      "2024-12-07 16:55:32,051 - srap_logging - INFO - Number of items: 227\n",
      "2024-12-07 16:55:32,052 - srap_logging - INFO - ----------------------------------------------------------------------------------------------------\n",
      "2024-12-07 16:55:32,052 - srap_logging - INFO - Scraping page 11/13...\n",
      "2024-12-07 16:55:32,054 - srap_logging - INFO - Skipping download: axius\\page_11.html already exists.\n",
      "2024-12-07 16:55:32,128 - srap_logging - INFO - Number of items: 227\n",
      "2024-12-07 16:55:32,129 - srap_logging - INFO - ----------------------------------------------------------------------------------------------------\n",
      "2024-12-07 16:55:32,130 - srap_logging - INFO - Scraping page 12/13...\n",
      "2024-12-07 16:55:32,131 - srap_logging - INFO - Skipping download: axius\\page_12.html already exists.\n",
      "2024-12-07 16:55:32,206 - srap_logging - INFO - Number of items: 227\n",
      "2024-12-07 16:55:32,207 - srap_logging - INFO - ----------------------------------------------------------------------------------------------------\n",
      "2024-12-07 16:55:32,209 - srap_logging - INFO - Scraping page 13/13...\n",
      "2024-12-07 16:55:32,210 - srap_logging - INFO - Skipping download: axius\\page_13.html already exists.\n",
      "2024-12-07 16:55:32,256 - srap_logging - INFO - Number of items: 227\n"
     ]
    }
   ],
   "source": [
    "axius.scrap('axius')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 16:55:37,866 - srap_logging - INFO - Skipping download: inmocasal\\page_1.html already exists.\n",
      "2024-12-07 16:55:37,948 - srap_logging - INFO - Número de páginas: 9\n",
      "2024-12-07 16:55:37,949 - srap_logging - INFO - Total Properties: 9\n",
      "2024-12-07 16:55:37,950 - srap_logging - INFO - ----------------------------------------------------------------------------------------------------\n",
      "2024-12-07 16:55:37,952 - srap_logging - INFO - Scraping page 1/9...\n",
      "2024-12-07 16:55:37,953 - srap_logging - INFO - Skipping download: inmocasal\\page_1.html already exists.\n",
      "2024-12-07 16:55:38,049 - srap_logging - INFO - Number of items: 227\n",
      "2024-12-07 16:55:38,050 - srap_logging - INFO - ----------------------------------------------------------------------------------------------------\n",
      "2024-12-07 16:55:38,050 - srap_logging - INFO - Scraping page 2/9...\n",
      "2024-12-07 16:55:38,051 - srap_logging - INFO - Skipping download: inmocasal\\page_2.html already exists.\n",
      "2024-12-07 16:55:38,140 - srap_logging - INFO - Number of items: 227\n",
      "2024-12-07 16:55:38,142 - srap_logging - INFO - ----------------------------------------------------------------------------------------------------\n",
      "2024-12-07 16:55:38,144 - srap_logging - INFO - Scraping page 3/9...\n",
      "2024-12-07 16:55:38,144 - srap_logging - INFO - Skipping download: inmocasal\\page_3.html already exists.\n",
      "2024-12-07 16:55:38,230 - srap_logging - INFO - Number of items: 227\n",
      "2024-12-07 16:55:38,232 - srap_logging - INFO - ----------------------------------------------------------------------------------------------------\n",
      "2024-12-07 16:55:38,233 - srap_logging - INFO - Scraping page 4/9...\n",
      "2024-12-07 16:55:38,234 - srap_logging - INFO - Skipping download: inmocasal\\page_4.html already exists.\n",
      "2024-12-07 16:55:42,478 - srap_logging - INFO - Number of items: 227\n",
      "2024-12-07 16:55:42,479 - srap_logging - INFO - ----------------------------------------------------------------------------------------------------\n",
      "2024-12-07 16:55:42,480 - srap_logging - INFO - Scraping page 5/9...\n",
      "2024-12-07 16:55:42,481 - srap_logging - INFO - Skipping download: inmocasal\\page_5.html already exists.\n",
      "2024-12-07 16:55:42,559 - srap_logging - INFO - Number of items: 227\n",
      "2024-12-07 16:55:42,560 - srap_logging - INFO - ----------------------------------------------------------------------------------------------------\n",
      "2024-12-07 16:55:42,561 - srap_logging - INFO - Scraping page 6/9...\n",
      "2024-12-07 16:55:42,561 - srap_logging - INFO - Skipping download: inmocasal\\page_6.html already exists.\n",
      "2024-12-07 16:55:42,636 - srap_logging - INFO - Number of items: 227\n",
      "2024-12-07 16:55:42,637 - srap_logging - INFO - ----------------------------------------------------------------------------------------------------\n",
      "2024-12-07 16:55:42,637 - srap_logging - INFO - Scraping page 7/9...\n",
      "2024-12-07 16:55:42,638 - srap_logging - INFO - Skipping download: inmocasal\\page_7.html already exists.\n",
      "2024-12-07 16:55:42,714 - srap_logging - INFO - Number of items: 227\n",
      "2024-12-07 16:55:42,715 - srap_logging - INFO - ----------------------------------------------------------------------------------------------------\n",
      "2024-12-07 16:55:42,716 - srap_logging - INFO - Scraping page 8/9...\n",
      "2024-12-07 16:55:42,717 - srap_logging - INFO - Skipping download: inmocasal\\page_8.html already exists.\n",
      "2024-12-07 16:55:42,792 - srap_logging - INFO - Number of items: 227\n",
      "2024-12-07 16:55:42,793 - srap_logging - INFO - ----------------------------------------------------------------------------------------------------\n",
      "2024-12-07 16:55:42,794 - srap_logging - INFO - Scraping page 9/9...\n",
      "2024-12-07 16:55:42,795 - srap_logging - INFO - Skipping download: inmocasal\\page_9.html already exists.\n",
      "2024-12-07 16:55:42,868 - srap_logging - INFO - Number of items: 227\n"
     ]
    }
   ],
   "source": [
    "inmocasal.scrap('inmocasal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALIZACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud properties: 227\n",
      "Longitud new properties: 0\n",
      "\n",
      "Conteo de categorías en 'properties':\n",
      "inmobiliaria\n",
      "axius        147\n",
      "inmocasal     80\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Conteo de categorías en 'new_properties':\n",
      "Series([], Name: count, dtype: int64)\n",
      "\n",
      "Total de elementos en 'properties' por categorías: 227\n",
      "Total de elementos en 'new_properties' por categorías: 0\n"
     ]
    }
   ],
   "source": [
    "# Cargar los DataFrames\n",
    "df = pd.read_pickle('results/properties.pkl')\n",
    "df_new = pd.read_pickle('results/new_properties.pkl')\n",
    "\n",
    "# Imprimir la longitud de cada DataFrame\n",
    "print(f'Longitud properties: {len(df)}')\n",
    "print(f'Longitud new properties: {len(df_new)}')\n",
    "\n",
    "# Contar elementos por categorías en la columna 'inmobiliaria'\n",
    "categorias_df = df['inmobiliaria'].value_counts()\n",
    "categorias_df_new = df_new['inmobiliaria'].value_counts()\n",
    "\n",
    "# Imprimir conteo por categorías\n",
    "print(\"\\nConteo de categorías en 'properties':\")\n",
    "print(categorias_df)\n",
    "\n",
    "print(\"\\nConteo de categorías en 'new_properties':\")\n",
    "print(categorias_df_new)\n",
    "\n",
    "# Imprimir totales\n",
    "total_properties = categorias_df.sum()\n",
    "total_new_properties = categorias_df_new.sum()\n",
    "\n",
    "print(f\"\\nTotal de elementos en 'properties' por categorías: {total_properties}\")\n",
    "print(f\"Total de elementos en 'new_properties' por categorías: {total_new_properties}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELIMINAR REGISTROS PARA PRUEBA DE NUEVAS VIVIENDAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df['inmobiliaria'] != 'inmocasal']\n",
    "# df.to_pickle('results/properties.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad inicial de registros:\n",
      "221\n",
      "Cantidad final de registros:\n",
      "215\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el DataFrame desde el archivo pickle\n",
    "df = pd.read_pickle('results/properties.pkl')\n",
    "print(\"Cantidad inicial de registros:\", len(df))\n",
    "\n",
    "# Agrupar por la columna de inmobiliarias y eliminar 3 registros de cada grupo\n",
    "for name, group in df.groupby('inmobiliaria'):\n",
    "    if len(group) > 3:  # Verificar que haya al menos 3 registros\n",
    "        # Seleccionar los 3 primeros registros del grupo para eliminar\n",
    "        to_delete = group.iloc[:3].index\n",
    "        \n",
    "        # Eliminar los registros del DataFrame original\n",
    "        df = df.drop(to_delete)\n",
    "\n",
    "# Guardar el DataFrame actualizado en un archivo pickle\n",
    "df.to_pickle('results/properties.pkl')\n",
    "print(\"Cantidad final de registros:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud properties: 215\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle('results/properties.pkl')\n",
    "print(f'Longitud properties: {len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
